version: '3.8'

services:
  crawlrouter:
    container_name: crawlrouter
    build: https://github.com/loorisr/crawlrouter.git
    ports:
      - "8000:8000"
    networks:
      - default
    environment:
      - SCRAPE_BACKEND=crawl4ai
      - SEARCH_BACKEND=searxng
      - SEARXNG_ENDPOINT=http://searxng:8080
      - CRAWL4AI_API_KEY=my_private_api_token
      - CRAWL4AI_ENDPOINT=http://crawl4ai:11235
      - CRAWL4AI_TIMEOUT=30
    security_opt:
      - no-new-privileges=true
    read_only: true
    restart: unless-stopped
    
  crawl4ai: # build to have the latest version
    build: 
      context: https://github.com/unclecode/crawl4ai.git
      args:
        PYTHON_VERSION: "3.10"
        INSTALL_TYPE: basic
        ENABLE_GPU: false
    restart: unless-stopped
    networks:
      - default
    environment:
      - MAX_CONCURRENT_TASKS=5
      - CRAWL4AI_API_TOKEN=my_private_api_token
    volumes:
      - /dev/shm:/dev/shm
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11235/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
      
  searxng:
    container_name: searxng
    image: searxng/searxng:latest
    environment:
      - BASE_URL=http://127.0.0.1:8080
      - PUID=1000
      - PGID=1000
    volumes:
      - /home/docker/searxng:/etc/searxng # enable json format in settings.yml https://docs.searxng.org/admin/settings/settings_search.html
    networks:
      - default
    restart: unless-stopped
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - DAC_OVERRIDE
      
